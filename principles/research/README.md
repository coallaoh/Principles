# Principles for Research

Research is about dealing with uncertainty. It is about inventing ideas and methods that have not existed before. You are never sure if your ideas and methods will work out in a month, in a year, or in a decade. Sometimes, you will need to make a radical viewpoint that goes against the majority. You do not know whether and when people will start to listen to you.

A good approach to dealing with uncertainties is to introduce “anchors”. I have my own set of principles for research that provide a good prior for anchoring my approach to the uncertainties. They provide the rule-of-thumb guidance on the strategy to tackle research problems and the effective mindset for building collaborations with others.

Those principles are firm anchors in the short term, but they do get updated in the long term. As I gather more data from direct and indirect experience, I will be able to correct and refine the existing principles and introduce new ones. The document will be updated accordingly.

This document is aimed for three types of audience:

- Junior researchers: They might find this a good starting point to build their own principles towards a successful research career.
- Collaborators: They will understand the core values I pursue in research.
- My students: Both of the above apply to my students.

## 1. Academic integrity

There are some commonsense rules that I expect myself and collaborators to live up to:

- Never steal someone else’s idea;
- Proactively credit those who helped; and
- Do not lie with numbers.

Apart from those commonsense rules, one must conform to the regulations and policies for each academic venue: conferences, journals, workshops, summer schools, etc. Examples include guidelines on the anonymity of authors and reviewers, dual submission, and plagiarism.

Academic integrity forms the fundamental base of your academic reputation. Aim for **never losing it** throughout your academic career. Once you lose your reputation, it is nearly impossible to recover.

## 2. Communication, collaboration, and argumentation

Research involves lots of communication, collaboration, and argumentation. There are many common pitfalls that could hinder the research progress and effective exchange of ideas and opinions. I summarise them below.

### 2-a. Question the authority

Authority comes in many forms in academia. It can be whether one has a PhD or not; whether one has written a paper on a certain topic or not; whether one has majored in a certain subject or not; whether one is older than you and has generally more life experience than you do.

Authority **never** logically supports the soundness of an argument. A professor who has written 100 papers on topic ABC is not exempt from the duty to provide evidence for their claims related to topic ABC. Authority only sets an expectation that the person will find good supporting evidence for their arguments.

Another form of authority in academia comes in the form of popularity. For example, the fact that most researchers evaluate their methods under the protocol DEF does not excuse one to follow the same protocol DEF. Every researcher must re-examine the practices and procedures based on their own soundness, independent of their popularity.

### 2-b. Do not rely on your own authority

As much as we must watch out for others who cling to authority, we should watch ourselves carefully if they are making arguments based on our own authority. Relying on authority will become more and more tempting in our research careers because we will be granted shiny titles, higher social status, and greater impact. We will learn that flashing our authority is a quick way to convince our correctness. This is a threat to the scientific progress which requires logical arguments and critical scrutiny. This is why we **always** need to make efforts to not take advantage of whatever authority we have to make our point. The habit sticks.

Some practical guide. Avoid starting your turn saying “speaking as someone who has majored in XYZ” or “from my N years of career in industry”. Basing your argument on your experience or knowledge is fine, but your example shall be more precise. Tell others “which materials and results from your major” and “what specific anecdote from your industrial experience” support your argument. There’s a fine difference between presenting evidence that are precisely chosen to support your argument versus alluding to your authority.

### 2-c. Research is about making a breakthrough

Research is not about making reviewers happy. It is about finding new problems that people have overlooked and coming up with a creative solution. More broadly, research is about changing the way people think. There are types of research that are optimized for pleasing reviewers. Such research may be worthless for the actual progress. We shall not shy away from making bold claims and confronting reviewers and critics, if necessary. “Because others do” is the worst reason. We do not follow others. We lead.

### 2-d. Brutal honesty

Progress is impossible without criticism. The first attempt we make is almost always full of error and nonsense, whether it be a research agenda, a piece of code, or the first draft for the paper. There is a long way to go between the initial work and the final product. If we put too much energy into choosing the right words, we may fail to make the needed progress. We need to be ready to make brutal criticism on others’ work and be ready to take such from the others.

One needs to clearly separate the assessment on the work from the one on the person who did it. One should be very careful with the assessment on the person because that leaves a strong memory and impact on the person’s life. But it is okay to criticize their work directly, quickly, and even brutally, as long as we share the principle that the critique on one’s work is separate from the critique on the person. We know that even great people make shit, especially for their first attempts. It is our duty to let them quickly go beyond that state by being honest.

### 2-e. Open-mindedness

While it is crucial as scientists to have critical views, we should be careful not to be harsh and cynical on everything.

One crucial occasion when we must refrain from being critical is at the inception stage of an idea. As researchers, we make things that lack the right words and concepts yet. It’s often challenging to convince the audience of one's new great idea because they are bound to existing words and concepts, which in turn bound the audience's imagination to existing things and stuff. Great ideas can sound boring and familiar at first.

When talking about exciting new research ideas, our basic attitude shall be welcoming, curious, and forgiving.
- **Welcoming**: Do not neglect anyone who comes to you with new insights and ideas, as much as your situation allows.
- **Curious**: Assume that we do not fully understand the marvellous insights hidden in the person in front of you. It is a human instinct to attach a familiar label to a novel idea; fight that instinct. Refrain from saying “oh I know what you’re talking about”.
- **Relaxed**: Do not demand each other to use more concrete language and mathematical formulation to describe the idea. They can come later. We need to acknowledge the fundamental limitations of language as the container for great ideas.

You can help the other person formulate the idea into language and mathematics. However, you need to make it clear that you are only suggesting to help the formulation, not criticising or judging it yet. You need to continuously synchronise with the person if your suggested formulation agrees with the marvellous insights hidden in the other person. Be careful because this "help" may also kill the potentially great idea, if not done right.

### 2-f. On respect and trust

As harmful is an excessive criticism of fledgling ideas (see open-mindedness above), it also significantly slows down a research project. When we work on a project, we do not question every single claim and idea produced by every single teammate. We acknowledge the expertise of team members and take most of the claims without further verification. As team members, we respect and trust each other. Such bonds make a team productive and successful.

The crucial ingredient for building such a rapport is that all of us must be able to defend our claims upon request. Such reliability underlies the respect and trust we have in each other. This makes a crucial distinction between respect (and trust) against "clinging to authority" (see above). When you are leaning on the authority of others, you avoid a critical assessment of their claims even when requesting such is necessary, typically because you do not want to confront them.

### 2-g. On expertise

How do we build a team where everyone shows mutual respect and trust and thus expedites discussion and progress? We do that by hiring a team of experts. I believe Ray Dalio's definition of "believable people" comes close to whom I would consider an "expert". Ray describes "believable people" as "people who have successfully accomplished the thing in question at least three times, and who have great explanation of the cause-effect relationships that lead them to their conclusions". The explanation of the cause-effect relationships is crucial, in my opinion, to assure the transferability of their past success to future ones. From the AI-research perspective, I would consider a person an expert if they have led at least three successful research projects as the first author (i.e. main planner, main coder, and main writer) for the respective conference papers. They must additionally provide a convincing story leading to successful research outcomes.

Side note: I believe a PhD program is a good opportunity for a student to acquire their expertise. Graduation requirements in various labs range from two to three top-tier conference papers written as the first author. I believe it nicely summarises the pathway to an expert. Indeed, there will be many individual cases where this simplistic rule doesn't fit, but this gives a rough guide on the ideal outcome of PhD studies.

### 2-h. Keeping a good dose of criticism

A critical mind must be the default mode for a researcher because we strive for the truth and progress. At the same time, we need to be aware of the downside of excessive criticism. It can kill ideas and slow down innovation. I can't build a manual for the "right" amount of criticism in every possible individual case. One will need to rely on the best guess and adjust their degrees of criticism on the fly. It is challenging indeed. However, I believe one will get better at this over time, as long as one is aware of the danger in both extremes and do their best to keep the balance.



## 3. Towards low-risk, high-return research

In 2015, at the beginning of my research career, I barely knew how to handle uncertainties and resulting risks. I was constantly worried that I need to make the next experiment work out. My first paper was a lucky one because my reproduction of a baseline method outperformed the original results without special tricks. After this paper, I was under great pressure that I need to replicate the luck. Indeed, trying to replicate luck is the worst way to deal with uncertainty, but I didn't know other ways then.

As of 2022, I have led and participated in more than 20 successful research projects. Along the way, I have learned some skills for producing stable and predictable research outputs, while not significantly compromising research impact and venturesomeness. I will share them below.

### 3-a. If the problem is too complex, break it down

It is often impractical to throw solutions at a complex problem, hoping that one of them will work out. This is a typical example of relying on your luck. Indeed, if you have an understanding of the underlying mechanisms for the complex problem, this method may work out. If you do not, then it is not advisable to tackle the problem in one go.

For any problem P, we can always find a sub-problem of P that can be solved arbitrarily easily. Break a complex problem down into simpler sub-problems. Break down the sub-problems recursively until they become easy enough to come up with sub-solutions. In the most extreme case, the sub-problem will become outright trivial (and thus solvable). A less rigorous intuition around the Intermediate Value Theorem tells us that there must be a sub-problem somewhere in the middle that is easy enough for a solution.

An example from AI research. Instead of tackling a problem pertaining to a large-scale, real-world dataset like ImageNet (high-resolution images of natural scenes taken with cameras), you set up the problem with toy datasets like MNIST (low-resolution black-and-white handwritten digits). If your solution doesn't work on MNIST, then there is no way your solution will work at the ImageNet scale. If it works on MNIST, then you finally go beyond MNIST and look for other remaining challenges.

The advantage of tackling a smaller problem is that you will understand the mechanisms much better. By designing the sub-problems such that they cover different types of challenges, we learn which solution is particularly effective for which challenge. The resulting insights will later help tackle the original complex problem.

One may worry that tackling a smaller problem is a low-risk, low-return strategy. I do not believe so. The impact of solving a smaller problem can be surprisingly high when the sub-problem is a common issue for multiple complex problems. By solving the common problem, you provide a common tool for multiple applications.

Attempting to address a complex problem at once increases the risk of spending time and money without any return. I believe a safe and quick way to solve it is to address its sub-problems sequentially and understand the mechanisms on the way.



### 3-b. Understand first, then solve

It is difficult to come up with a solution without understanding the problem. This is quite obvious and I believe many will already agree. But what I *really* mean by “understand first” is that one should be ready to invest a substantial amount of time (perhaps even a full project) dedicated to understanding the problem. It’s not enough to *think hard* about the problem. One should really come up with dedicated hypotheses and experiments just for the sake of understanding the problem. 

From the risk-management perspective, such “understanding first” projects are often safer bets. If the research question and the problem themselves are interesting, the impact of your work do not depend on the outcome of your experiments - both the observations “A<B” and “B<A” are interesting and impactful. The paper on shape-texture bias in ImageNet-trained models [a] is a good example. The paper highlights a critical difference between humans’ and CNNs’ processing of visual inputs. By formulating an interesting question, you can let such “understanding first” projects enjoy a reduced risk compared to “solution first” projects that often require a state-of-the-art result. 

Such “understand first” projects may also lead to a greater impact, compared to a “solution first” work. If one shares nice insights early on, researchers in the relevant community will parallelise the subsequent efforts to come up with solutions. For example, [a] has led to a number of methods addressing the shape-texture bias in ImageNet models in just a couple of years.

[a] Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A. Wichmann, Wieland Brendel. ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness. ICLR 2018.

### 3-c. Do not follow a dead-end

There are research topics that are popular today but are likely to face a dead end in the long run. Dead ends come in different shapes: 

- trying to solve an impossible problem;
- improvements in infrastructure (e.g. data and compute) render the problem less relevant; or
- a strong technology may easily supersede the current art.

Contributions to a dead-end technology are not as bad as it sounds. There can be immense short-term benefits to the problems of today; that is why the such topics are popular in the first place. One could be productive within such dead-end topics in the short run, given that a large number of people are contributing to the community. Even after the technology becomes irrelevant, some technological byproducts may prove useful for other topics. Researchers may also be acknowledged for their transferable skills and experience; working on a dead-end topic does not imply a dead end for one's career.

Nonetheless, my personal preference is to pursue a long-term research impact. I prefer research topics that are less likely to run into a dead end. At least, there must be an exit strategy even if they do. Such topics have the following patterns:

- instead of tackling an impossible problem, you look into the minimal-cost methods to make the problem possible again;
- improved infrastructure will further necessitate the technology in question; and
- developed technologies are sufficiently unique and cannot easily be superseded by subsequent developments.


### 3-d. No-creation principle for information

A typical dead-end research topic is one where you try to get more information from a system than what you give as input. I have a strong belief that this is fundamentally impossible. I call this the “no-creation principle for information”. This is analogous to the law of conservation of energy in physics: a closed system cannot create energy on its own.

Exactly what do the “information” and “closed system” mean in a machine learning context? I will provide a hand-wavy description for now. I hope to provide a more rigorous definition and claim in the future. A machine learning algorithm takes a set of observations (training data) and learning recipes (e.g. hyperparameters and design choices) as input and returns a model as an output. My version of the no-creation principle is that “a model does not contain more information than the sum of information in observations and learning recipes”. That is, your model’s performance on the test set is bounded from above by the amount of information given during training. 

This sounds obvious, but attempts to break this rule are seen from time to time in machine learning. One such example is the Weakly-Supervised Object Localisation (WSOL) task. The aim is to train a model that *knows* how to differentiate foreground and background pixels while only feeding it with global image labels (e.g. whether a cat is in the image or not). Generally, there may be spurious background correlations that are stronger than the foreground features (e.g. duck’s feet are less visible in duck images than water features). Thus, the training dataset generally lacks sufficient information to discriminate between foreground and background features. And yet, researchers aim to extract such information from a system that does not contain it [b]. This is one of the many examples in machine learning where the no-creation principle is challenged. I try not to pursue such research topics unless the aim is to fix the issue.

[b] Junsuk Choe, Seong Joon Oh, Seungho Lee, Sanghyuk Chun, Zeynep Akata, Hyunjung Shim. Evaluating Weakly Supervised Object Localization Methods Right. CVPR 2020.


### 3-e. Research strategy: *Always staying close to perfect performance*

![Asset 1](https://github.com/user-attachments/assets/2927962d-5ce3-45b7-a84a-6e4489bcfc4d)

Many students, once they start their PhD, aim to tackle very challenging problems. They often have the ambition to raise a challenging benchmark accuracy from 20% to 90% by the end of their studies. However, this approach is very risky for several reasons:

- We often lack knowledge of the theoretical upper limit. In other words, we don’t know the success criterion. When is it time to stop improving and celebrate?
- A single idea is unlikely to achieve the target. Reaching a high level of performance will require a sequence of ideas. However, combining ideas in complex ways often leads to diminishing returns, making it difficult to reach the intended goal.

![Asset 3](https://github.com/user-attachments/assets/2b8533a4-9e6f-400a-9007-16a50346e6c5)

Instead, I propose a strategy of *always staying close to perfect performance*.

1. Identify an easy problem setup where a perfect performance can be achieved with a simple solution. From a theoretical perspective, this involves adding more simplifying assumptions. Empirically, this might mean providing additional data or resources for the system. While this setup may be far from reality, it gives a clear sense of best-case performance, serving as a realistic north star throughout the project.

1. Introduce challenges incrementally, such as by removing each simplifying assumption or reducing resources available to the method. Stop when the performance significantly drops from the "perfect" level and devise a specific solution to address the gap. Once the performance is reasonably good again, move on to introduce additional challenges, iterating this process.

1. Conclude either when a realistic problem setup with reasonable performance is achieved, or when maintaining reasonable performance becomes unfeasible under increased difficulty. In both cases, report the findings and outcomes to the audience as your contribution.

The benefit of this approach is that it breaks a larger problem into manageable parts. Instead of tackling multiple challenges at once, this method isolates each issue, allowing you to develop targeted solutions. It prevents the inefficient “throwing solutions at a problem” approach. This is also similar to debugging software: each commit (solution) must pass tests (achieve close-to-perfect performance) before being merged into the main branch (advancing to more challenging problems).


### 3-f. Hedge the bets with a research portfolio

Risk management consists of two components: (1) focus your resources on low-risk, high-return projects as much as possible (see above) and (2) deal with the remaining uncertainty by hedging your bets. Depending on your seniority, you may have different capacities to run projects in parallel. A PhD student will probably have only 1 or 2 threads (one thread == capacity for one project). It is important for them to choose low-risk, high-return topics to ensure more consistent research performances. For a postdoc, you may have 2-5 threads in parallel. That already lets you diversify your research portfolio. 

### 3-g. Everything will be alright

So far, I talked about ways to manage risks in research and keep things under control. But the truth is: you can’t achieve zero risk — and that’s fine. 

I personally find it hard to live with unpredictability, but I learned that this is inevitable in research. However hard I plan ahead, there will most likely be unpredicted outcomes that will ask me to improvise. Eventually, the final research outputs will be composed less of the clever initial idea and more of the improvisations and hacks in the course of the project.

Such improvisations cannot be prepared ahead of time. I believe the best way to learn to improvise is to frequently put yourself on the spot and force yourself to improvise. I suggest jumping into your project and getting your hands dirty as soon as the basic risk management principles above are considered. I can’t explain all the mysterious mechanisms behind how the remaining uncertainties in research get resolved. But over years, I have gained confidence that I will eventually figure it out, either by myself or with help of others. I have seen many others doing the same. Everything will be alright for you too.
